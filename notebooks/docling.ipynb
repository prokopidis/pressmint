{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bee832e",
   "metadata": {},
   "source": [
    "# Docling tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3cb39",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646abeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "import litellm\n",
    "from litellm import completion\n",
    "from tqdm.notebook import tqdm # Import tqdm for notebooks\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    TesseractCliOcrOptions,\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"..\") / \"data/Newspapers/\"\n",
    "subdirs = [p for p in data_folder.iterdir() if p.is_dir()]\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "random_pdfs = []\n",
    "pdf_paths = []\n",
    "\n",
    "for subdir in subdirs:\n",
    "    pdfs = list(subdir.glob(\"*.pdf\"))\n",
    "    if pdfs:\n",
    "        chosen = random.choice(pdfs)\n",
    "        random_pdfs.append(chosen)\n",
    "    for pdf_path in pdfs:\n",
    "        pdf_paths.append(pdf_path)\n",
    "\n",
    "logger.info(f\"Found {len(pdf_paths)} to process\")\n",
    "# Comment out to process random pdfs\n",
    "# pdf_paths = random_pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1d153",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb08aba",
   "metadata": {},
   "source": [
    "### Docling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.table_structure_options.do_cell_matching = True\n",
    "\n",
    "# Any of the OCR options can be used:EasyOcrOptions, TesseractOcrOptions, TesseractCliOcrOptions, OcrMacOptions(Mac only), RapidOcrOptions\n",
    "# ocr_options = EasyOcrOptions(force_full_page_ocr=True)\n",
    "# ocr_options = TesseractOcrOptions(force_full_page_ocr=True)\n",
    "# ocr_options = OcrMacOptions(force_full_page_ocr=True)\n",
    "# ocr_options = RapidOcrOptions(force_full_page_ocr=True)\n",
    "\n",
    "ocr_options = TesseractCliOcrOptions(force_full_page_ocr=True)\n",
    "pipeline_options.ocr_options = ocr_options\n",
    "pipeline_options.ocr_options.lang = [\"ell\"]\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "converter_str = \"docling\"\n",
    "markdown_docling_paths = []\n",
    "json_docling_paths = []\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    markdown_path = pdf_path.parent / (pdf_path.stem + f\".{converter_str}.md\")\n",
    "    json_path = pdf_path.parent / (pdf_path.stem + f\".{converter_str}.json\")\n",
    "    if markdown_path.exists() and json_path.exists():\n",
    "        return json_path, markdown_path\n",
    "\n",
    "    doc = converter.convert(pdf_path).document\n",
    "\n",
    "    json_result = doc.export_to_dict()\n",
    "    md = doc.export_to_markdown()\n",
    "\n",
    "    with open(markdown_path, \"w\") as outf:\n",
    "        outf.write(md)\n",
    "    with open(json_path, \"w\") as outf:\n",
    "        outf.write(json.dumps(json_result, ensure_ascii=False))\n",
    "    return json_path, markdown_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-joblib (sequential) version\n",
    "results = []\n",
    "for pdf_path in tqdm(pdf_paths, desc=\"Processing PDFs\"):\n",
    "    print(f\"Processing: {pdf_path.parent / (pdf_path.name)}\")\n",
    "    res = process_pdf(pdf_path)\n",
    "    print(f\"Exported to: {pdf_path.parent / (pdf_path.stem + f'.{converter_str}.md')}\")\n",
    "    results.append(res)\n",
    "\n",
    "# Unpack results\n",
    "json_docling_paths = []\n",
    "markdown_docling_paths = []\n",
    "for res in results:\n",
    "    if res:\n",
    "        json_docling_paths.append(res[0])\n",
    "        markdown_docling_paths.append(res[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A joblib version to experiment with\n",
    "\n",
    "# Set the number of parallel jobs (adjust as needed)\n",
    "# n_jobs = 4\n",
    "\n",
    "# results = Parallel(n_jobs=n_jobs)(\n",
    "#     delayed(lambda pdf_path: (\n",
    "#         print(f\"Processing: {pdf_path.parent / (pdf_path.name)}\"),\n",
    "#         res := process_pdf(pdf_path),\n",
    "#         print(f\"Exported to: {pdf_path.parent / (pdf_path.stem + f'.{converter_str}.md')}\"),\n",
    "#         res\n",
    "#     )[-1])(pdf_path) for pdf_path in tqdm(pdf_paths, desc=\"Processing PDFs\")\n",
    "# )\n",
    "\n",
    "# # Unpack results\n",
    "# json_docling_paths = []\n",
    "# markdown_docling_paths = []\n",
    "# for res in results:\n",
    "#     if res:\n",
    "#         json_docling_paths.append(res[0])\n",
    "#         markdown_docling_paths.append(res[1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pressmint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
